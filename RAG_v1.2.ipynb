{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:46:40.436370Z",
     "start_time": "2024-07-25T22:46:37.328685Z"
    }
   },
   "source": "! pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all firecrawl-py PyMuPDF sentence_transformers python-dotenv langchain_intro\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in ./venv/lib/python3.12/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: langchain_community in ./venv/lib/python3.12/site-packages (0.2.10)\r\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.12/site-packages (0.7.0)\r\n",
      "Requirement already satisfied: langchainhub in ./venv/lib/python3.12/site-packages (0.1.20)\r\n",
      "Requirement already satisfied: chromadb in ./venv/lib/python3.12/site-packages (0.5.5)\r\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.2.11)\r\n",
      "Requirement already satisfied: langgraph in ./venv/lib/python3.12/site-packages (0.1.14)\r\n",
      "Requirement already satisfied: tavily-python in ./venv/lib/python3.12/site-packages (0.3.5)\r\n",
      "Requirement already satisfied: gpt4all in ./venv/lib/python3.12/site-packages (2.7.0)\r\n",
      "Requirement already satisfied: firecrawl-py in ./venv/lib/python3.12/site-packages (0.0.20)\r\n",
      "Requirement already satisfied: PyMuPDF in ./venv/lib/python3.12/site-packages (1.24.9)\r\n",
      "Requirement already satisfied: sentence_transformers in ./venv/lib/python3.12/site-packages (3.0.1)\r\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.0.1)\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement langchain_intro (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for langchain_intro\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:31:49.468296Z",
     "start_time": "2024-07-25T21:31:45.859614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## index\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Load PDF documents\n",
    "pdf_file_paths = [\"./data/Medical Policy FY 23-24.pdf\", \"./data/Provident fund policy.pdf\"]\n",
    "\n",
    "docs_list = []\n",
    "for pdf_path in pdf_file_paths:\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    try:\n",
    "        loaded_docs = loader.load()\n",
    "        docs_list.extend(loaded_docs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path}: {e}\")\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "doc_splitter = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Filter and clean metadata\n",
    "filtered_doc = []\n",
    "for doc in doc_splitter:\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k: v for k, v in doc.metadata.items() if isinstance(v, (str, int, float, bool))}\n",
    "        filtered_doc.append(Document(page_content=doc.page_content, metadata=clean_metadata))\n",
    "\n",
    "# Add to vectorDB\n",
    "embedding = GPT4AllEmbeddings(model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\", gpt4all_kwargs={'allow_download': 'True'})\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=filtered_doc,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "id": "2c187aaa96e17864",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T21:32:17.807851Z",
     "start_time": "2024-07-25T21:32:17.805723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# local_llm = 'gemma'\n",
    "local_llm = 'llama3'\n",
    "# local_llm = 'mistral'"
   ],
   "id": "3f06c3e5637a9a3b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:12:18.932242Z",
     "start_time": "2024-07-25T23:12:18.928528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n"
   ],
   "id": "d5a4fe8c4407cb0e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:15:25.566470Z",
     "start_time": "2024-07-25T23:15:14.271691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "context_template_str = \"\"\"system You are an assistant for question-answering tasks. Use the following context to answer the question. Avoid phrases like \"Based on the provided context\". Explain the answer in the end. and make a heading with paragraph.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer: assistant\"\"\"\n",
    "\n",
    "context_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=context_template_str,\n",
    "    )\n",
    ")\n",
    "\n",
    "context_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"{question}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "context_messages = [context_system_prompt, context_human_prompt]\n",
    "\n",
    "context_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    messages=context_messages,\n",
    ")\n",
    "\n",
    "\n",
    "context_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | context_prompt_template | llm | output_parser\n",
    "\n",
    "context_question = \"Does original receipts must be submitted?\"\n",
    "context_answer = context_chain.invoke(context_question)\n",
    "print(context_answer)"
   ],
   "id": "c259dea7d4fcdc16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Original Receipt Submission Requirement**\n",
      "\n",
      "According to the Provident Fund Policy V2.0, original receipts must be submitted within 30 days of loan disbursement for construction on a plot. This is stated in point 2 under \"Documents to be submitted\" on page 6.\n",
      "\n",
      "However, it's worth noting that this requirement only applies to construction on a plot and not to other types of withdrawals or expenses. For medicines, tests, procedures, etc., original receipts are required as per the Medical Policy FY 23-24.\n",
      "\n",
      "**Key Takeaway**\n",
      "\n",
      "Original receipts must be submitted within 30 days of loan disbursement for construction on a plot, but this requirement may vary depending on the type of expense or withdrawal.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T23:23:28.958391Z",
     "start_time": "2024-07-25T23:23:23.521657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_context_system_template_str = \"\"\"system You are an assistant for question-answering tasks. Answer the question concisely and directly. If you dont know the answer the say dont know.\n",
    "Question: {question}\n",
    "Answer: assistant\"\"\"\n",
    "\n",
    "no_context_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=no_context_system_template_str,\n",
    "    )\n",
    ")\n",
    "\n",
    "no_context_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"{question}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "no_context_messages = [no_context_system_prompt, no_context_human_prompt]\n",
    "\n",
    "no_context_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    messages=no_context_messages,\n",
    ")\n",
    "\n",
    "no_context_chain = {\"question\": RunnablePassthrough()} | no_context_prompt_template | llm | output_parser\n",
    "\n",
    "no_context_question = \"what is 911 event\"\n",
    "no_context_answer = no_context_chain.invoke(no_context_question)\n",
    "print(no_context_answer)"
   ],
   "id": "11f1188dfa78fca1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 9/11 event, also known as the September 11 attacks, was a series of coordinated terrorist attacks that occurred on September 11, 2001. On that day, four commercial airplanes were hijacked by terrorists affiliated with al-Qaeda. Two planes crashed into the Twin Towers of the World Trade Center in New York City, causing massive damage and loss of life. Another plane crashed into the Pentagon in Arlington, Virginia, and the fourth plane, believed to be heading for the White House or the U.S. Capitol Building, crashed in a field in Pennsylvania after passengers attempted to overpower the hijackers. In total, nearly 3,000 people were killed in the attacks.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T22:45:41.243161Z",
     "start_time": "2024-07-25T22:45:41.239439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def get_current_wait_time(hospital: str) -> int | str:\n",
    "    \"\"\"Dummy function to generate fake wait times\"\"\"\n",
    "\n",
    "    if hospital not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        return f\"Hospital {hospital} does not exist\"\n",
    "\n",
    "    # Simulate API call delay\n",
    "    time.sleep(1)\n",
    "\n",
    "    return random.randint(0, 10000)"
   ],
   "id": "a9c76e4d06b82a29",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents import (\n",
    "    create_openai_functions_agent,\n",
    "    Tool,\n",
    "    AgentExecutor,\n",
    ")\n",
    "from langchain import hub\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Reviews\",\n",
    "        func=context_chain.invoke,\n",
    "        description=\"\"\"Useful when you need to answer questions\n",
    "        about patient reviews or experiences at the hospital.\n",
    "        Not useful for answering questions about specific visit\n",
    "        details such as payer, billing, treatment, diagnosis,\n",
    "        chief complaint, hospital, or physician information.\n",
    "        Pass the entire question as input to the tool. For instance,\n",
    "        if the question is \"What do patients think about the triage system?\",\n",
    "        the input should be \"What do patients think about the triage system?\"\n",
    "        \"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Waits\",\n",
    "        func=get_current_wait_time,\n",
    "        description=\"\"\"Use when asked about current wait times\n",
    "        at a specific hospital. This tool can only get the current\n",
    "        wait time at a hospital and does not have any information about\n",
    "        aggregate or historical wait times. This tool returns wait times in\n",
    "        minutes. Do not pass the word \"hospital\" as input,\n",
    "        only the hospital name itself. For instance, if the question is\n",
    "        \"What is the wait time at hospital A?\", the input should be \"A\".\n",
    "        \"\"\",\n",
    "    ),\n",
    "]\n"
   ],
   "id": "2173eb995c9dcf7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
