{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:25.943875Z",
     "start_time": "2024-08-06T13:09:23.604861Z"
    }
   },
   "source": "! pip install -U langchain_community PyMuPDF python-docx tiktoken sentence_transformers",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in ./venv/lib/python3.12/site-packages (0.2.11)\r\n",
      "Requirement already satisfied: PyMuPDF in ./venv/lib/python3.12/site-packages (1.24.9)\r\n",
      "Requirement already satisfied: python-docx in ./venv/lib/python3.12/site-packages (1.1.2)\r\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.12/site-packages (0.7.0)\r\n",
      "Requirement already satisfied: sentence_transformers in ./venv/lib/python3.12/site-packages (3.0.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.0.31)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\r\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.2.12)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.2.28)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.1.93)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (8.5.0)\r\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in ./venv/lib/python3.12/site-packages (from PyMuPDF) (1.24.9)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in ./venv/lib/python3.12/site-packages (from python-docx) (5.2.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./venv/lib/python3.12/site-packages (from python-docx) (4.12.2)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken) (2024.5.15)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./venv/lib/python3.12/site-packages (from sentence_transformers) (4.42.4)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from sentence_transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.12/site-packages (from sentence_transformers) (2.3.1)\r\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (from sentence_transformers) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from sentence_transformers) (1.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./venv/lib/python3.12/site-packages (from sentence_transformers) (0.23.5)\r\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:25.959581Z",
     "start_time": "2024-08-06T13:09:25.946090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from docx import Document as DocxDocument\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ],
   "id": "de8584fc491b01a4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:25.963183Z",
     "start_time": "2024-08-06T13:09:25.960260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# local_llm = 'gemma'\n",
    "local_llm = 'llama3'\n",
    "# local_llm = 'llama3.1'\n",
    "# local_llm = 'mistral'"
   ],
   "id": "eb3df2736e097052",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:40.953443Z",
     "start_time": "2024-08-06T13:09:25.964991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory to check\n",
    "cascade_directory = \"./data/cascade\"\n",
    "policy_directory = \"./data/policy\"\n",
    "\n",
    "directories = [cascade_directory, policy_directory]\n",
    "\n",
    "\n",
    "# Lists to store file paths\n",
    "pdf_file_paths = []\n",
    "docx_file_paths = []\n",
    "\n",
    "# Check for files in the directory\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        print(filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_file_paths.append(os.path.join(directory, filename))\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            docx_file_paths.append(os.path.join(directory, filename))\n",
    "\n",
    "docs_list = []\n",
    "\n",
    "# Load PDF files\n",
    "for pdf_path in pdf_file_paths:\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    try:\n",
    "        loaded_docs = loader.load()\n",
    "        docs_list.extend(loaded_docs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path}: {e}\")\n",
    "\n",
    "# Load DOCX files\n",
    "for docx_path in docx_file_paths:\n",
    "    try:\n",
    "        docx = DocxDocument(docx_path)\n",
    "        full_text = []\n",
    "        for para in docx.paragraphs:\n",
    "            full_text.append(para.text)\n",
    "        docx_text = '\\n'.join(full_text)\n",
    "        docs_list.append(Document(page_content=docx_text, metadata={\"source\": docx_path}))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {docx_path}: {e}\")\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "doc_splitter = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Filter and clean metadata\n",
    "filtered_doc = []\n",
    "for doc in doc_splitter:\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k: v for k, v in doc.metadata.items() if isinstance(v, (str, int, float, bool))}\n",
    "        filtered_doc.append(Document(page_content=doc.page_content, metadata=clean_metadata))\n",
    "\n",
    "# Add to vectorDB\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=filtered_doc,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ],
   "id": "9bd8ddc5090bbe7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "Cascade features.pdf\n",
      "CASCADE_USERS.docx\n",
      "CASCADE_ADMINISTRATION_GUIDE.docx\n",
      "CASCADE_USER_GUIDE_V6 (USER JOURNEYS).docx\n",
      "DCL_WORKFLOW.pdf\n",
      "MORTGAGE_GUIDE-compressed.pdf\n",
      "DCF_WORKFLOW.pdf\n",
      "CASCADE_FEATURES.docx\n",
      "Medical Policy FY 23-24.pdf\n",
      ".DS_Store\n",
      "Provident fund policy.pdf\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:40.980063Z",
     "start_time": "2024-08-06T13:09:40.966920Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOllama(model=local_llm, temperature=0)\n",
   "id": "987503fda911b7c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:09:41.171906Z",
     "start_time": "2024-08-06T13:09:40.982155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ],
   "id": "382a597a556bbe91",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_history_aware_retriever() missing 1 required positional argument: 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 12\u001B[0m\n\u001B[1;32m      1\u001B[0m contextualize_q_system_prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mGiven a chat history and the latest user question \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124mwhich might reference context in the chat history, formulate a standalone question \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124mwhich can be understood without the chat history. Do NOT answer the question, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124mjust reformulate it if needed and otherwise return it as is.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      5\u001B[0m contextualize_q_prompt \u001B[38;5;241m=\u001B[39m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_messages(\n\u001B[1;32m      6\u001B[0m     [\n\u001B[1;32m      7\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, contextualize_q_system_prompt),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     ]\n\u001B[1;32m     11\u001B[0m )\n\u001B[0;32m---> 12\u001B[0m history_aware_retriever \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_history_aware_retriever\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontextualize_q_prompt\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: create_history_aware_retriever() missing 1 required positional argument: 'prompt'"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "qa_system_prompt = \"\"\"system You are an assistant for question-answering tasks. Use the following context to answer the question. Avoid phrases like \"Based on the provided context\". Explain the answer in the end. and make a heading with paragraph.\n",
    "Question: {input}\n",
    "Context: {context}\n",
    "Answer: assistant\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ],
   "id": "7a00448a664d1e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chat_history = []\n",
   "id": "2f25f8155878c917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Explain the significance of document management within Cascadeâ„¢.\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])"
   ],
   "id": "88365544ab61b66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(ai_msg_1[\"answer\"])",
   "id": "7dcb84c02f0aea05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1d86f039c1247053",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
