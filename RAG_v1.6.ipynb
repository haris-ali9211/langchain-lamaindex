{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-06T14:12:00.668592Z",
     "start_time": "2024-08-06T14:11:59.572906Z"
    }
   },
   "source": [
    "# Install necessary libraries\n",
    "!pip install pytesseract Pillow requests langchain_community langchain_core langchain_huggingface pytesseract langchain PIL "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in ./venv/lib/python3.12/site-packages (0.3.10)\r\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.12/site-packages (10.4.0)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (2.32.3)\r\n",
      "Requirement already satisfied: langchain_community in ./venv/lib/python3.12/site-packages (0.2.11)\r\n",
      "Requirement already satisfied: langchain_core in ./venv/lib/python3.12/site-packages (0.2.28)\r\n",
      "Requirement already satisfied: langchain_huggingface in ./venv/lib/python3.12/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: llama-index in ./venv/lib/python3.12/site-packages (0.10.57)\r\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.2.12)\r\n",
      "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.12/site-packages (from pytesseract) (24.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests) (2024.7.4)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.0.31)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.1.93)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (1.26.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (8.5.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain_core) (1.33)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib/python3.12/site-packages (from langchain_core) (2.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain_core) (4.12.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (0.23.5)\r\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (3.0.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (0.19.1)\r\n",
      "Requirement already satisfied: transformers>=4.39.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (4.42.4)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in ./venv/lib/python3.12/site-packages (from llama-index) (0.2.9)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.12)\r\n",
      "Requirement already satisfied: llama-index-core==0.10.57 in ./venv/lib/python3.12/site-packages (from llama-index) (0.10.57)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.2.5)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in ./venv/lib/python3.12/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.27)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.8)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.30)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in ./venv/lib/python3.12/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (2024.5.0)\r\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (3.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (3.8.1)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (1.37.0)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (2.2.2)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (4.66.4)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core==0.10.57->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.4)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\r\n",
      "Requirement already satisfied: llama-cloud>=0.0.9 in ./venv/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.0.9)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in ./venv/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index) (0.4.9)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain_core) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain_core) (2.20.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.3.1)\r\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.57->llama-index) (4.4.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.57->llama-index) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.57->llama-index) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.57->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.57->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.57->llama-index) (1.4.2)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.57->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.57->llama-index) (3.0.3)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.57->llama-index) (1.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.57->llama-index) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.57->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.57->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.57->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:13:35.146146Z",
     "start_time": "2024-08-06T15:13:35.136474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ],
   "id": "9035e031e8539a13",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:13:36.714776Z",
     "start_time": "2024-08-06T15:13:36.427115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the image of the income statement\n",
    "image_path = './data/test/is.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Use Tesseract to extract text from the image\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "# Save the extracted text to a text file\n",
    "output_text_file = './data/test/extracted_text.txt'\n",
    "with open(output_text_file, 'w') as file:\n",
    "    file.write(extracted_text)\n",
    "\n",
    "print(f\"Extracted text has been saved to {output_text_file}\")"
   ],
   "id": "233d9b0d08436dec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text has been saved to ./data/test/extracted_text.txt\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:13:38.481028Z",
     "start_time": "2024-08-06T15:13:38.474256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# local_llm = 'gemma'\n",
    "local_llm = 'llama3'\n",
    "# local_llm = 'llama3.1'\n",
    "# local_llm = 'mistral'"
   ],
   "id": "c9459bef927ca769",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:13:45.527742Z",
     "start_time": "2024-08-06T15:13:41.403902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory to check\n",
    "isParserData = \"./data/test\"\n",
    "directories = [isParserData]\n",
    "\n",
    "# List to store file paths\n",
    "txt_file_paths = []\n",
    "\n",
    "# Check for files in the directory\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            txt_file_paths.append(os.path.join(directory, filename))\n",
    "\n",
    "docs_list = []\n",
    "\n",
    "# Load TXT files\n",
    "for txt_path in txt_file_paths:\n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "            txt_content = file.read()\n",
    "        docs_list.append(Document(page_content=txt_content, metadata={\"source\": txt_path}))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {txt_path}: {e}\")\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=250, chunk_overlap=0)\n",
    "doc_splitter = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Filter and clean metadata\n",
    "filtered_doc = []\n",
    "for doc in doc_splitter:\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k: v for k, v in doc.metadata.items() if isinstance(v, (str, int, float, bool))}\n",
    "        filtered_doc.append(Document(page_content=doc.page_content, metadata=clean_metadata))\n",
    "\n",
    "# Add to vectorDB\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=filtered_doc,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "id": "b7941d7d486f4035",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:12:52.507266Z",
     "start_time": "2024-08-06T14:12:52.503976Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOllama(model=local_llm, temperature=0)\n",
   "id": "7444cde8f8427e1e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:13:32.203102Z",
     "start_time": "2024-08-06T14:13:32.199276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ],
   "id": "a95f620d56a84fdb",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:13:38.591175Z",
     "start_time": "2024-08-06T14:13:38.588290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_system_prompt = \"\"\"system You are an assistant for question-answering tasks. Use the following context to answer the question. Avoid phrases like \"Based on the provided context\". Explain the answer in the end. and make a heading with paragraph.\n",
    "Question: {input}\n",
    "Context: {context}\n",
    "Answer: assistant\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ],
   "id": "95d04c84dc9b76d8",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:13:44.533037Z",
     "start_time": "2024-08-06T14:13:44.530868Z"
    }
   },
   "cell_type": "code",
   "source": "chat_history = []",
   "id": "3e44893dcb0b91e3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:15:06.021732Z",
     "start_time": "2024-08-06T14:14:45.488147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"can you analyze this data and explain\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])"
   ],
   "id": "a00df7ecbad672ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T14:15:20.284190Z",
     "start_time": "2024-08-06T14:15:20.281698Z"
    }
   },
   "cell_type": "code",
   "source": "print(ai_msg_1[\"answer\"])\n",
   "id": "69202e34325d6578",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Financial Analysis of a Company**\n",
      "\n",
      "The provided financial data is for the year ended September 28, 2019. Here's an analysis of the key figures:\n",
      "\n",
      "**Revenue and Gross Profit**\n",
      "The company reported net sales of $4,358,100, with a gross profit of $1,619,386. This indicates that the company has a strong revenue stream and is able to maintain a decent margin on its products or services.\n",
      "\n",
      "**Operating Expenses**\n",
      "Total operating expenses stood at $854,159, which includes selling and operating expenses ($560,430) and general and administrative expenses ($293,729). This suggests that the company has a significant expense base, which may impact its profitability.\n",
      "\n",
      "**Operating Income and Other Income**\n",
      "The company reported an operating income of $765,227, indicating that it was able to generate profits from its core operations. Additionally, it had other income of $960, which contributed to its overall profitability.\n",
      "\n",
      "**Non-Operating Items**\n",
      "The company recorded a gain on financial instruments of $5,513 and a loss on foreign currency of $(12,649). These non-operating items had a net impact of $2,864 on the company's income. It also incurred interest expense of $(18,177).\n",
      "\n",
      "**Income Before Taxes and Net Income**\n",
      "The company reported an income before taxes of $740,874 and a net income of $483,232. This indicates that it was able to generate significant profits after accounting for taxes.\n",
      "\n",
      "Overall, the financial data suggests that the company has a strong revenue stream and is able to maintain decent profitability. However, its high operating expenses may impact its ability to generate profits in the long run. The non-operating items also had a significant impact on its income, which may not be sustainable in the future.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:31:47.388366Z",
     "start_time": "2024-08-06T15:31:47.386126Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "157d35458c82deb4",
   "outputs": [],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
