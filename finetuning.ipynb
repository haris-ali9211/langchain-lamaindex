{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T10:46:01.195181Z",
     "start_time": "2024-08-05T10:45:56.395228Z"
    }
   },
   "source": "!pip install transformers datasets torch\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.42.4)\r\n",
      "Collecting datasets\r\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from transformers) (3.15.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./venv/lib/python3.12/site-packages (from transformers) (0.23.5)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in ./venv/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.12/site-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (17.0.0)\r\n",
      "Collecting pyarrow-hotfix (from datasets)\r\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.2.2)\r\n",
      "Collecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from datasets)\r\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.12/site-packages (from datasets) (3.9.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m547.8/547.8 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m7.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m316.1/316.1 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.7/146.7 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, fsspec, dill, multiprocess, datasets\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2024.6.1\r\n",
      "    Uninstalling fsspec-2024.6.1:\r\n",
      "      Successfully uninstalled fsspec-2024.6.1\r\n",
      "Successfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-hotfix-0.6 xxhash-3.4.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T10:46:16.698258Z",
     "start_time": "2024-08-05T10:46:16.691990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your JSON data\n",
    "data = {\n",
    "    \"general_info\": {\n",
    "        \"title\": \"Cascade™ Loan Lifecycle Management Platform and User Guide\",\n",
    "        \"developer\": \"Unikrew Solutions Pvt. Ltd.\",\n",
    "        \"confidentiality\": \"Confidential © 2023\"\n",
    "    },\n",
    "    \"ui_ux_design\": {\n",
    "        \"methodology\": \"Human-centered design for productivity, combining exploratory and primary research techniques.\",\n",
    "        \"research_techniques\": \"Exploratory research and primary research through participant interviews to explore design concepts.\"\n",
    "    },\n",
    "    \"channels\": {\n",
    "        \"supported_channels\": [\"Mobile app\", \"Tablet app\", \"Web interface\"],\n",
    "        \"integration\": \"Integration with SMS, email, and WhatsApp banking platforms for notifications.\",\n",
    "        \"cross_channel_continuity\": \"Journey can start on one channel and continue on another.\"\n",
    "    },\n",
    "    \"customer_journey\": {\n",
    "        \"complete_customer_journey\": \"Covers from customer prospecting to digital onboarding, loan origination, loan management, and collections.\"\n",
    "    },\n",
    "    \"cascade_originations\": {\n",
    "        \"end_to_end_loan_origination\": \"Comprehensive coverage of the origination journey.\",\n",
    "        \"prospecting_and_lead_generation\": \"Prescreening potential customers, capturing data, and generating reports on conversion rates.\",\n",
    "        \"data_capturing\": \"Data entry and validation throughout the application lifecycle.\",\n",
    "        \"field_definition_and_validation\": \"Dynamic definition and validation of fields, including required/optional, length, and regular expressions.\",\n",
    "        \"dynamic_forms\": \"Addition of new fields and validations without development, adjusting fields on web and mobile interfaces.\"\n",
    "    },\n",
    "    \"credit_initiation_and_decision_making\": {\n",
    "        \"profile_checks\": [\"Fraud\", \"Anti-money laundering\", \"Political exposure\", \"Anti-terrorism\", \"Defaulter checks\"],\n",
    "        \"bureau_check_and_exposure\": \"Credit history checks, exposure sheet generation, and integration with Data Check.\",\n",
    "        \"limit_management\": \"Assignment of credit limits based on predefined criteria and historical loan data.\",\n",
    "        \"policy_engine\": \"Execution of predefined policies, including regulatory and internal risk management policies.\",\n",
    "        \"scoring_engine\": \"Generation of scorecards for decision-making using static or machine learning-based methods.\",\n",
    "        \"peer_benchmarking\": \"Providing benchmarks and percentiles for customer evaluation.\",\n",
    "        \"security_wise_lgd\": [\"Haircut percentage\", \"Collateral coverage\"],\n",
    "        \"pricing\": [\"Markup\", \"KIBOR\", \"Spread\", \"Processing fees\"]\n",
    "    },\n",
    "    \"approvals_and_recommendations\": {\n",
    "        \"application_routing_and_approval_hierarchy\": \"Management of application routing for approval and processing based on predefined conditions.\",\n",
    "        \"escalations\": \"Handling of escalation processes with notifications to higher authorities.\"\n",
    "    },\n",
    "    \"disbursement_and_client_documentation\": {\n",
    "        \"documentation\": \"Automated generation and management of documents with predefined templates.\",\n",
    "        \"disbursement_and_funds_movement\": \"Management of fund transactions and limit creation post-approval.\",\n",
    "        \"document_management\": \"Comprehensive document lifecycle management, including storage, archiving, and retrieval with indexing.\"\n",
    "    },\n",
    "    \"cascade_collections_optional_module\": {\n",
    "        \"data_ingestion\": \"Management of data feeding from Core Banking Systems or Cascade Asset Management.\",\n",
    "        \"strategy_and_queues\": \"Assignment of strategies and queues for loan accounts based on parameters like DPD (Days Past Due).\",\n",
    "        \"allocations\": \"Manual and automated allocation of loan accounts to collectors.\",\n",
    "        \"actions\": [\"Outgoing call\", \"Customer visit\", \"Promise to pay\"],\n",
    "        \"performance_management\": \"Management of collector performance and determination of commissions based on actions and repayments.\"\n",
    "    },\n",
    "    \"login_and_starting_workflow\": {\n",
    "        \"login_page\": \"Users log in with credentials to access the platform.\",\n",
    "        \"starting_a_workflow\": \"Steps to start a new workflow, including selecting a product and initiating a workflow based on user rights.\"\n",
    "    },\n",
    "    \"document_management\": {\n",
    "        \"uploading_documents\": \"Steps to upload documents, including dragging and dropping files, uploading new versions, and accessing previous versions.\",\n",
    "        \"trail_feature\": \"Allows users to view the stages and users involved in the application process.\"\n",
    "    },\n",
    "    \"lead_generation\": {\n",
    "        \"uploading_lead_generation_data_in_bulk\": \"Steps to upload lead generation data from an Excel file, including browsing, uploading, and managing entries.\"\n",
    "    },\n",
    "    \"product_workflows\": {\n",
    "        \"crop_ntb\": {\n",
    "            \"select_product\": \"Under the Workflows tab, select the product to start a new application.\",\n",
    "            \"fill_details\": \"Enter necessary details, including lead generation and AFO fields.\",\n",
    "            \"validate_and_proceed\": \"Validate the entered details and proceed to the next group.\",\n",
    "            \"credit_analyst_stage\": \"Create deviations if necessary and validate all fields.\",\n",
    "            \"checklist\": \"Upload required documents and run checks as specified.\",\n",
    "            \"approval\": \"Application goes through multiple recommendations and approvals from relevant accounts.\",\n",
    "            \"post_approval\": \"Fill post-approval documents, validate fields, and proceed to the next stage.\",\n",
    "            \"rcad_stage\": \"Complete the required fields, upload documents, and validate to proceed.\",\n",
    "            \"capu_stage\": \"Fill all required fields, validate, and proceed to completion and disbursement.\"\n",
    "        },\n",
    "        \"fishery_ntb\": {\n",
    "            \"select_product\": \"Under the Workflows tab, select the product to start a new application.\",\n",
    "            \"fill_details\": \"Enter necessary details, including lead generation and AFO fields.\",\n",
    "            \"validate_and_proceed\": \"Validate the entered details and proceed to the next group.\",\n",
    "            \"credit_analyst_stage\": \"Create deviations if necessary and validate all fields.\",\n",
    "            \"checklist\": \"Upload required documents and run checks as specified.\",\n",
    "            \"approval\": \"Application goes through multiple recommendations and approvals from relevant accounts.\",\n",
    "            \"post_approval\": \"Fill post-approval documents, validate fields, and proceed to the next stage.\",\n",
    "            \"rcad_stage\": \"Complete the required fields, upload documents, and validate to proceed.\",\n",
    "            \"capu_stage\": \"Fill all required fields, validate, and proceed to completion and disbursement.\"\n",
    "        },\n",
    "        \"poultry_ntb\": {\n",
    "            \"select_product\": \"Under the Workflows tab, select the product to start a new application.\",\n",
    "            \"fill_details\": \"Enter necessary details, including lead generation and AFO fields.\",\n",
    "            \"validate_and_proceed\": \"Validate the entered details and proceed to the next group.\",\n",
    "            \"credit_analyst_stage\": \"Create deviations if necessary and validate all fields.\",\n",
    "            \"checklist\": \"Upload required documents and run checks as specified.\",\n",
    "            \"approval\": \"Application goes through multiple recommendations and approvals from relevant accounts.\",\n",
    "            \"post_approval\": \"Fill post-approval documents, validate fields, and proceed to the next stage.\",\n",
    "            \"rcad_stage\": \"Complete the required fields, upload documents, and validate to proceed.\",\n",
    "            \"capu_stage\": \"Fill all required fields, validate, and proceed to completion and disbursement.\"\n",
    "        },\n",
    "        \"dairy_ntb\": {\n",
    "            \"select_product\": \"Under the Workflows tab, select the product to start a new application.\",\n",
    "            \"fill_details\": \"Enter necessary details, including lead generation and AFO fields.\",\n",
    "            \"validate_and_proceed\": \"Validate the entered details and proceed to the next group.\",\n",
    "            \"credit_analyst_stage\": \"Create deviations if necessary and validate all fields.\",\n",
    "            \"checklist\": \"Upload required documents and run checks as specified.\",\n",
    "            \"approval\": \"Application goes through multiple recommendations and approvals from relevant accounts.\",\n",
    "            \"post_approval\": \"Fill post-approval documents, validate fields, and proceed to the next stage.\",\n",
    "            \"rcad_stage\": \"Complete the required fields, upload documents, and validate to proceed.\",\n",
    "            \"capu_stage\": \"Fill all required fields, validate, and proceed to completion and disbursement.\"\n",
    "        },\n",
    "        \"crop_renewal\": {\n",
    "            \"select_product\": \"Under the Workflows tab, select the product to start a new application.\",\n",
    "            \"fill_details\": \"Enter necessary details, including lead generation and AFO fields.\",\n",
    "            \"validate_and_proceed\": \"Validate the entered details and proceed to the next group.\",\n",
    "            \"credit_analyst_stage\": \"Create deviations if necessary and validate all fields.\",\n",
    "            \"checklist\": \"Upload required documents and run checks as specified.\",\n",
    "            \"approval\": \"Application goes through multiple recommendations and approvals from relevant accounts.\",\n",
    "            \"post_approval\": \"Fill post-approval documents, validate fields, and proceed to the next stage.\",\n",
    "            \"rcad_stage\": \"Complete the required fields, upload documents, and validate to proceed.\",\n",
    "            \"capu_stage\": \"Fill all required fields, validate, and proceed to completion and disbursement.\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "  "
   ],
   "id": "d8bd79a540a8d6af",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T10:46:24.068254Z",
     "start_time": "2024-08-05T10:46:23.039622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Flatten the JSON data for easier processing\n",
    "def flatten_json(json_data):\n",
    "    flat_data = []\n",
    "\n",
    "    def recurse(key, value):\n",
    "        if isinstance(value, dict):\n",
    "            for subkey, subvalue in value.items():\n",
    "                recurse(f\"{key}.{subkey}\", subvalue)\n",
    "        else:\n",
    "            flat_data.append({\"text\": f\"{key}: {value}\"})\n",
    "\n",
    "    for main_key, main_value in json_data.items():\n",
    "        recurse(main_key, main_value)\n",
    "\n",
    "    return flat_data\n",
    "\n",
    "flat_data = flatten_json(data)\n",
    "\n",
    "# Create a Hugging Face dataset\n",
    "dataset = Dataset.from_list(flat_data)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# Print to check the data format\n",
    "print(dataset)\n"
   ],
   "id": "6bb8d0b57b39b169",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 73\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 9\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T10:46:39.990929Z",
     "start_time": "2024-08-05T10:46:32.124854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ],
   "id": "da3f0915adde6f5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "613fcc4c1aea406e8ba7d0162aaea7c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22f46073366a421281e1bbce3b7465d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e134306dfd64146a114aa2d9eb5cfda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede9522180574cdfb0b8471f18b0d60b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3ce47eaf9224870bb4fb52de06278a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72de701083b949ed95b959b487554f6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "797ec12dae0e44db9b3a91d35c410265"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:21:15.829960Z",
     "start_time": "2024-08-05T10:47:40.451622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ],
   "id": "fa61b816ae39ee50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e3b3cb795ec425396da6a849d879c47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "002f1c4c8afa4ef29e8ae2f445b50ae0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbd9f378a0bd44c18c82bdf0af5c1610"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6efad690a0941a99b63f700fe030dfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f974495aa1a34e1aa1b8eec99784c3af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0610f8e7a05548f1ac5b4be173209b18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dacc8f8fa2d8414e8352856a8ea48584"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harisali/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.07 GB, other allocations: 384.00 KB, max allowed: 18.13 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 26\u001B[0m\n\u001B[1;32m     18\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     19\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     20\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m     21\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtokenized_datasets[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     22\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mtokenized_datasets[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     23\u001B[0m )\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/transformers/trainer.py:1932\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1930\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1931\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1932\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1933\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1934\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1935\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1936\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1937\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/transformers/trainer.py:2089\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2087\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mprepare(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[1;32m   2088\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2089\u001B[0m         model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2090\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2091\u001B[0m     \u001B[38;5;66;03m# to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\u001B[39;00m\n\u001B[1;32m   2092\u001B[0m     model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mprepare(\n\u001B[1;32m   2093\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler\n\u001B[1;32m   2094\u001B[0m     )\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1304\u001B[0m, in \u001B[0;36mAccelerator.prepare\u001B[0;34m(self, device_placement, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m         \u001B[38;5;66;03m# MS-AMP will handle the device placement\u001B[39;00m\n\u001B[1;32m   1303\u001B[0m         device_placement \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[0;32m-> 1304\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfirst_pass\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_placement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_placement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1307\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_one(obj, device_placement\u001B[38;5;241m=\u001B[39md) \u001B[38;5;28;01mfor\u001B[39;00m obj, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(result, device_placement))\n\u001B[1;32m   1309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tpu_should_fix_optimizer \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmixed_precision \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp8\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp8_recipe_handler\u001B[38;5;241m.\u001B[39mbackend \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTE\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1310\u001B[0m     \u001B[38;5;66;03m# 2. grabbing new model parameters\u001B[39;00m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1305\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1302\u001B[0m         \u001B[38;5;66;03m# MS-AMP will handle the device placement\u001B[39;00m\n\u001B[1;32m   1303\u001B[0m         device_placement \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[1;32m   1304\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[0;32m-> 1305\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfirst_pass\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_placement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m obj, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(args, device_placement)\n\u001B[1;32m   1306\u001B[0m     )\n\u001B[1;32m   1307\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_one(obj, device_placement\u001B[38;5;241m=\u001B[39md) \u001B[38;5;28;01mfor\u001B[39;00m obj, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(result, device_placement))\n\u001B[1;32m   1309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tpu_should_fix_optimizer \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmixed_precision \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp8\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp8_recipe_handler\u001B[38;5;241m.\u001B[39mbackend \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTE\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1310\u001B[0m     \u001B[38;5;66;03m# 2. grabbing new model parameters\u001B[39;00m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1181\u001B[0m, in \u001B[0;36mAccelerator._prepare_one\u001B[0;34m(self, obj, first_pass, device_placement)\u001B[0m\n\u001B[1;32m   1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_data_loader(obj, device_placement\u001B[38;5;241m=\u001B[39mdevice_placement)\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_placement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_placement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer):\n\u001B[1;32m   1183\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_optimizer(obj, device_placement\u001B[38;5;241m=\u001B[39mdevice_placement)\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1428\u001B[0m, in \u001B[0;36mAccelerator.prepare_model\u001B[0;34m(self, model, device_placement, evaluation_mode)\u001B[0m\n\u001B[1;32m   1424\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1425\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt train a model that has been loaded in 8-bit precision with CPU or disk offload.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1426\u001B[0m         )\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m device_placement \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverify_device_map(model):\n\u001B[0;32m-> 1428\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1429\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evaluation_mode:\n\u001B[1;32m   1430\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m   1431\u001B[0m         DistributedType\u001B[38;5;241m.\u001B[39mMULTI_GPU,\n\u001B[1;32m   1432\u001B[0m         DistributedType\u001B[38;5;241m.\u001B[39mMULTI_MLU,\n\u001B[1;32m   1433\u001B[0m         DistributedType\u001B[38;5;241m.\u001B[39mMULTI_NPU,\n\u001B[1;32m   1434\u001B[0m         DistributedType\u001B[38;5;241m.\u001B[39mMULTI_XPU,\n\u001B[1;32m   1435\u001B[0m     ):\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:2796\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2791\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[1;32m   2792\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2793\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2794\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2795\u001B[0m         )\n\u001B[0;32m-> 2796\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1173\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1170\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1171\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 779 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m~/development/codeBase/langchain-lamaindex/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1159\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1153\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1154\u001B[0m             device,\n\u001B[1;32m   1155\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1156\u001B[0m             non_blocking,\n\u001B[1;32m   1157\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1158\u001B[0m         )\n\u001B[0;32m-> 1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 18.07 GB, other allocations: 384.00 KB, max allowed: 18.13 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e3673265fefeeaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
